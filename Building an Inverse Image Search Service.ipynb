{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Inverse Image Search Service\n",
    "\n",
    "Leveraging the power of transfer learning can be very useful in many applications. Particularly, in this notebook we'll harness the readiness of pre-trained network to build an inverse image search engine or, more clearly, a \"search by example\" service.\n",
    "\n",
    "Of course, all deep learning tasks begin with data acquisition, so this will be no different. \n",
    "\n",
    "The images we will use will be extracted from Wikipedia and then passed through a pre-trained network to compile a \"embedding\" dictionary that'll later on will allow us to fetch similar images using a simple nearest neighbor search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Let's import the libraries we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import random\n",
    "import os\n",
    "import base64\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from keras.models import Model\n",
    "from hashlib import md5\n",
    "import pickle\n",
    "from urllib.parse import unquote\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import HTML, Image as IPImage, display\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Images from Wikipedia\n",
    "\n",
    "Wikipedia is a great soure of knowledge in many formats. This, of course, includes visual data (i.e., images). Given we want our search service to be as flexible as possible, is our desire to gather a corpus of images as possible. Hence, Wikipedia is a great place to do so.\n",
    "\n",
    "The thing with the images in Wikipedia is that they represent concrete instances of things, which is not exactly what we need in this case. Instead, we want to return a picture that represents a dog as a species, instead of a specific one, such as Pluto.\n",
    "\n",
    "Wikipedia is parented with Wikidata, which structure is based around triplets of the form {subject, relation, object}, and has a great number of predicates encoded, many of them on top of Wikipedia. One of these predicates, called \"instance of\" is represented by P31. Using this predicate, we can get the images of the objects in the ends of this relationship. \n",
    "\n",
    "Here's a query expressed in Wikidata's query language to get this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''SELECT ?pic\n",
    "WHERE\n",
    "{\n",
    "    ?item wdt:P31 ?class . \n",
    "    ?class wdt:P18 ?pic\n",
    "}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the Wikidata using this query and unfold the resulting JSON into a list of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql'\n",
    "\n",
    "data = requests.get(url, params={'query': query, 'format': 'json'})\n",
    "print(data.text)\n",
    "data = data.json()\n",
    "\n",
    "pages_urls = [result['pic']['value'] for result in data['results']['bindings']]\n",
    "\n",
    "print(f'Number of fetched pages urls: {len(pages_urls)}')\n",
    "print(random.sample(pages_urls, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results correspond to URLs sto the image pages, not the images themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pages_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
